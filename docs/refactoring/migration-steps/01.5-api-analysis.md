# Step 1.5: API Surface Analysis (CRITICAL - WAS MISSING!)

## Overview

Before creating ANY interfaces or adapters, analyze the complete API surface area of components to be refactored. This step was missing from the original migration and caused runtime failures.

## Duration

1 week (Between test stabilization and abstraction layer)

## Why This Is Critical

- **Prevents runtime failures** from missing methods
- **Ensures full compatibility** during migration  
- **Reveals actual usage patterns** vs assumed patterns
- **Identifies dead code** that can be removed
- **Documents the true contract** that must be maintained

## Objectives

1. Map ALL methods and attributes used on each component
2. Identify usage frequency and patterns
3. Document the complete API contract
4. Create compatibility test suite
5. Generate accurate interfaces based on reality

## Detailed Steps

### Day 1-2: Build Analysis Tools

#### 1.1 Create AST-based Analyzer
```python
# Create: tools/analyze_api_usage.py
"""Analyze actual API usage across codebase"""

import ast
from collections import defaultdict
from pathlib import Path

class APIUsageAnalyzer(ast.NodeVisitor):
    """Find all method calls and attribute access on target objects"""
    
    def __init__(self, target_vars):
        self.target_vars = target_vars
        self.method_calls = defaultdict(list)
        self.attr_access = defaultdict(list)
        self.current_file = None
    
    def analyze_codebase(self, root_path):
        """Analyze all Python files"""
        for py_file in Path(root_path).rglob("*.py"):
            if "__pycache__" not in str(py_file):
                self.analyze_file(py_file)
        return self.generate_report()
```

#### 1.2 Create Runtime Tracker
```python
# Create: tools/runtime_api_tracker.py
"""Track API usage at runtime"""

import functools
from collections import defaultdict

class RuntimeAPITracker:
    """Monkey-patch classes to track method calls"""
    
    def __init__(self):
        self.calls = defaultdict(int)
    
    def track_class(self, cls):
        """Add tracking to all methods of a class"""
        for name in dir(cls):
            if not name.startswith('_'):
                attr = getattr(cls, name)
                if callable(attr):
                    setattr(cls, name, self._track_call(name, attr))
    
    def _track_call(self, name, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            self.calls[name] += 1
            return func(*args, **kwargs)
        return wrapper
```

### Day 3-4: Run Analysis

#### 2.1 Static Analysis
```bash
# Analyze storage backend usage
python tools/analyze_api_usage.py \
    --target-class StorageBackend \
    --scan-dir src/mdm \
    --output storage_api_report.json

# Analyze feature generator usage  
python tools/analyze_api_usage.py \
    --target-class FeatureGenerator \
    --scan-dir src/mdm \
    --output features_api_report.json

# Analyze dataset registrar usage
python tools/analyze_api_usage.py \
    --target-class DatasetRegistrar \
    --scan-dir src/mdm \
    --output registrar_api_report.json
```

#### 2.2 Dynamic Analysis
```python
# Run test suite with tracking
import pytest
from runtime_api_tracker import RuntimeAPITracker

tracker = RuntimeAPITracker()
tracker.track_class(StorageBackend)
tracker.track_class(FeatureGenerator)
tracker.track_class(DatasetRegistrar)

# Run tests
pytest.main()

# Generate report
tracker.generate_report("runtime_api_usage.json")
```

### Day 5: Generate Interfaces

#### 3.1 Auto-generate Protocol Interfaces
```python
# Generate complete interfaces based on usage
from api_analysis import load_analysis, generate_interface

# Load analysis
static_data = load_analysis("storage_api_report.json")
runtime_data = load_analysis("runtime_api_usage.json")

# Merge and generate
all_methods = merge_api_data(static_data, runtime_data)
interface_code = generate_interface(
    "IStorageBackend",
    all_methods,
    include_docstrings=True,
    include_usage_stats=True
)

# Save interface
with open("src/mdm/interfaces/storage_complete.py", "w") as f:
    f.write(interface_code)
```

#### 3.2 Create Compatibility Matrix
```markdown
## Storage Backend API Compatibility Matrix

| Method | Usage Count | Old Backend | New Backend | Status |
|--------|-------------|-------------|-------------|--------|
| query() | 142 | ✅ | ❌ | MISSING |
| create_table_from_dataframe() | 89 | ✅ | ❌ | MISSING |
| get_engine() | 78 | ✅ | ✅ | OK |
| close_connections() | 23 | ✅ | ❌ | MISSING |
| database_exists() | 45 | ✅ | ❌ | MISSING |
```

### Day 6-7: Create Compatibility Tests

#### 4.1 Generate Test Suite
```python
# Auto-generate tests for each discovered method
def generate_compatibility_tests(api_methods):
    """Generate tests ensuring all methods exist"""
    
    test_code = '''
import pytest
from old_module import OldClass
from new_module import NewClass

class TestAPICompatibility:
    """Ensure new implementation has all methods of old"""
'''
    
    for method in api_methods:
        test_code += f'''
    def test_{method}_exists(self):
        """Verify {method} is implemented"""
        assert hasattr(NewClass, "{method}")
        
    def test_{method}_signature(self):
        """Verify {method} has compatible signature"""
        old_sig = inspect.signature(OldClass.{method})
        new_sig = inspect.signature(NewClass.{method})
        assert old_sig == new_sig
'''
    
    return test_code
```

#### 4.2 Create Usage-based Tests
```python
# Generate tests based on actual usage patterns
def generate_usage_tests(usage_patterns):
    """Create tests that mirror real usage"""
    
    tests = []
    for pattern in usage_patterns:
        test = f'''
def test_{pattern.name}():
    """Test based on {pattern.source_file}:{pattern.line}"""
    backend = get_backend()
    {pattern.setup_code}
    
    # Actual usage from codebase
    {pattern.usage_code}
    
    # Verify expected behavior
    {pattern.assertion_code}
'''
        tests.append(test)
    
    return "\n".join(tests)
```

## Analysis Outputs

### Required Deliverables

1. **Complete API Inventory** (`api_inventory.json`)
   ```json
   {
     "StorageBackend": {
       "methods": {
         "query": {"count": 142, "locations": [...]},
         "create_table_from_dataframe": {"count": 89, "locations": [...]}
       },
       "attributes": {
         "engine": {"count": 23, "locations": [...]}
       }
     }
   }
   ```

2. **Generated Interfaces** (`interfaces/storage_complete.py`)
   ```python
   class IStorageBackend(Protocol):
       """Complete interface based on actual usage"""
       
       def query(self, sql: str, params: Optional[Dict] = None) -> pd.DataFrame:
           """Used 142 times across codebase"""
           ...
   ```

3. **Compatibility Test Suite** (`tests/test_api_compatibility.py`)
   ```python
   def test_all_storage_methods_present():
       """Ensure new backend has ALL methods"""
       required_methods = load_api_inventory()["StorageBackend"]["methods"]
       for method in required_methods:
           assert hasattr(NewStorageBackend, method)
   ```

4. **Migration Risk Report** (`migration_risks.md`)
   ```markdown
   ## High Risk Methods (>50 usages)
   - query(): 142 usages - MUST maintain exact signature
   - create_table_from_dataframe(): 89 usages - Critical for data loading
   
   ## Medium Risk Methods (10-50 usages)
   - database_exists(): 45 usages - Used in registration flow
   ```

## Common Pitfalls to Avoid

### ❌ DON'T: Design Interfaces First
```python
# WRONG: Designing ideal interface without analysis
class IStorageBackend(Protocol):
    def execute(self, query: str) -> Result:  # Nobody uses this!
        ...
```

### ✅ DO: Analyze First, Design Second
```python
# RIGHT: Interface based on actual usage
class IStorageBackend(Protocol):
    def query(self, sql: str) -> pd.DataFrame:  # Used 142 times!
        ...
```

### ❌ DON'T: Trust Your Memory
"I think we only use these 5 methods" - WRONG!

### ✅ DO: Measure Everything
"The analyzer found 23 methods and 15 attributes in use" - RIGHT!

### ❌ DON'T: Skip Edge Cases
"Nobody uses that old method" - Someone does!

### ✅ DO: Include Everything First
Include ALL methods, mark deprecated ones, remove only after migration.

## Success Criteria

- [ ] 100% of methods used in codebase are documented
- [ ] Generated interfaces include ALL discovered methods
- [ ] Compatibility tests pass for both old and new implementations  
- [ ] No "AttributeError" possible during migration
- [ ] Usage frequency documented for prioritization

## Tools and Scripts

All analysis tools are available in the `tools/` directory:
- `analyze_api_usage.py` - Static AST analysis
- `runtime_api_tracker.py` - Dynamic runtime tracking  
- `generate_interfaces.py` - Interface generation
- `compatibility_test_generator.py` - Test generation

## Next Steps

Only after completing this analysis:
1. Proceed to [Step 2: Abstraction Layer](02-abstraction-layer.md)
2. Use generated interfaces as the specification
3. Create adapters that implement the COMPLETE interface
4. Begin gradual migration with confidence

Remember: **You can't refactor what you haven't measured!**